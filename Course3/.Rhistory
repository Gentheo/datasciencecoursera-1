andy[which(andy[,"Day"] == 30), "Weight"]
andy_start <- andy[1, "Weight"]
andy_end <- andy[30, "Weight"]
andy_loss <- andy_start - andy_end
andy_loss
?list.files
files <- list.files("diet_data")
files
head(read.csv(files[3]))
files_full <- list.files("diet_data", full.names = TRUE)
files_full
head(read.csv(files_full[3]))
andy_david <- rbind(andy, read.csv(files_full[2]))
head(andy_david)
tail(andy_david)
day_25 <- andy_david[which(andy_david$Day == 25), ]
day_25
for (i in 1:5) {print(i)}
dat <- data.frame()
for (i in 1:5) {
dat <- rbind(dat, read.csv(files_full[i]))
}
str(dat)
median(dat$Weight, na.rm=TRUE)
dat_30 <- dat[which(dat[, "Day"] == 30),]
dat_30
median(dat_30$Weight)
weightmedian(directory = "diet_data", day = 20)
source('~/Professional/DataScience/course2/wt_med.R')
weightmedian(directory = "diet_data", day = 20)
weightmedian("diet_data", 4)
?seq_along
?str
swirl()
ls -l
ls()
View(c1)
View(c1)
?rm
x <- list(a = matrix(1:4, 2, 2), b = matrix(1:6, 3, 2))
y <- lapply(x, function(n) n[[,1]])
y <- lapply(x, function(n) n[,1])
y
x <- c(rnorm(10), runif(10), rnorm(10, 1))
f <- gl(3, 10)
split(x,f)
library(datasets)
head(airquality)
split(airquality, airquality$Month)
s <- split(airquality, airquality$Month)
str(s)
lapply(s, function(x){})
lapply(s, function(x) {colMeans(x[,"Ozone", "Solar.R","Wind"])})
lapply(s, function(x) {colMeans(x[, c("Ozone", "Solar.R","Wind")])})
lapply(s, function(x) {colMeans(x[, c("Ozone", "Solar.R","Wind")], rm.na=TRUE)})
lapply(s, function(x) {colMeans(x[, c("Ozone", "Solar.R","Wind")],rm.na=TRUE)})
sapply(s, function(x) { colMeans(x[, c("Ozone", "Solar.R","Wind")], na.rm = =TRUE) })
sapply(s, function(x) { colMeans(x[, c("Ozone", "Solar.R","Wind")], na.rm = TRUE) })
x <- rnorm(10)
f1 <- gl(2, 5)
f2 <- gl(5, 2)
f1
f2
interaction(f1,f2)
x <- c(rnorm(10), runif(10), rnorm(10, 1))
f <- gl(3, 10)
f
tapply(x, f, mean)
tapply(x, f, range)
x <- matrix(rnorm(200), 20, 10)
x
apply(x,2,mean)
apply(x,1,mean)
a <- array(rnorm(2 * 2 * 10), c(2, 2, 10))
str(a)
a
b<-rnorm(2*2*10)
b
array(b,c(2, 2, 10))
array$b
library(datasets)
data("iris")
?iris
head(iris)
s<-split(iris,iris$Species)
s
colMeans(s,"Sepal.Length")
colMeans$Sepal.Length
colMeans(s$Sepal.Length)
colMeans(s[Sepal.Length])
lapply(colMeans[,"Sepal.Length"])
lapply(s,colMeans[,"Sepal.Length"])
lapply(s,function (x){colMeans(x[,"Sepal.Length"]})
lapply(s,function (x){colMeans(x[,"Sepal.Length"])}
)
lapply(s,function (x){colMeans(x[,c("Sepal.Length")])}
)
library(datasets)
data("iris")
?iris
str(iris)
s<- split(iris, iris$Species)
str(s)
lapply(s, function(x) {})
lapply(s, function(x) {colMeans(x[,c("Sepal.Length","Sepal.Width")]) })
data("mtcars")
?mtcars
tapply(mpg,cyl,mean)
with(mtcars, tapply(mpg,cyl,mean))
split(mtcars,mtcars$cyl)
sapply(mtcars, cyl, mean)
sapply(mtcars, mtcars$cyl, mean)
lapply(mtcars, mean)
tapply(mtcars$mpg,mtcars$cyl,mean)
apply(mtcars,2,mean)
tapply(mtcars$hp,mtcars$cyl,mean)
82.63636-122.28571
debug(ls)
ls
ls()
q
quit
exit
undebug(ls)
Q
Q
Q
Q
n
n
sapply(split(mtcars$mpg,mtcars$cyl),mean)
colMeans(iris)
apply(iris,2,mean)
dataset(iris)
data("iris")
apply(iris,2,mean)
apply(iris[,1:4],2,mean)
class(iris)
colMeans(iris)
library(viridisLite)
info
library(iris)
dim(iris)
str(iris)
head(iris)
s <- iris$Species
l <- split(iris,s)
head(l)
tapply(iris,s,colMeans)
head(s)
s
tapply(iris,iris$Species,colMeans)
apply(iris,2,mean)
apply(iris,2,mean, na.rm=TRUE)
apply(iris[,1:4],2,mean)
s
l
apply(l$setosa[,1:4],2,mean)
apply(iris[,1:4],2,mean)
colMeans(iris)
colMeans(iris[,1;4])
colMeans(iris[,1:4])
lapply(iris[,1:4],mean)
sapply(iris[,1:4],mean)
below_ave <- function(x) { ave <- mean(x) return[x[x > ave]]}
below_ave <- function(x) { ave <- mean(x) return[x[x > ave]]}
below_ave <- function(x) {
ave <- mean(x)
return(x[x > ave])
}
below_ave(iris$Sepal.Length)
tapply(iris$Sepal.Width, iris$Species, median)
tapply(iris$Sepal.Width, iris$Species, mean)
apply(l$setosa[,1:4],2,mean)
data(beavers)
str(beaver1)
apply(t(beaver1),1,max)
apply(mtcars,2,mean)
tapply(mtcars$mpg,mtcars$cyl,mean)
by(iris[,1:4],iris$Species,colMeans)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
str(mtcars)
sapply(split(mtcars$hp, mtcars$cyl), mean)
82.63636 - 209.21429
ls()
install.packages("RMySQL"); library(RMySQL)
install.packages("RMySQL")
install.packages(c("callr", "caTools", "cli", "colorspace", "fs", "git2r", "glue", "knitr", "lazyeval", "Matrix", "openssl", "processx", "purrr", "Rcpp", "RCurl", "readxl", "rmarkdown", "rstudioapi", "stringi", "sys", "tibble", "tidyr", "tinytex"))
library("RMySQL", lib.loc="/Library/Frameworks/R.framework/Versions/3.5/Resources/library")
library(RMySQL)
ucsc <- dbConnect(MySQL(),user = "genome", host="genome-mysql.soe.ucsc.edu")
result <- dbGetQuery(ucscDb, "show databases;"); dbDisconnect(ucscDb)
ucsc <- dbConnect(MySQL(),user = "genome", db="hg19",host="genome-mysql.soe.ucsc.edu")
allTables <- dbListTables(hg19)
ucsc <- dbConnect(MySQL(),user = "genome", db="hg19",host="genome-mysql.cse.ucsc.edu")
allTables <- dbListTables(hg19)
ucsc <- dbConnect(RMySQL::MySQL(),dbname="test",host="genome-mysql.cse.ucsc.edu", user = "genome")
ucsc <- dbConnect(RMySQL::MySQL(),host="genome-mysql.cse.ucsc.edu", user = "genome")
dbListTables(ucsc)
ucsc <- dbConnect(RMySQL::MySQL(), dbname="ailMel1", host="genome-mysql.cse.ucsc.edu", user = "genome")
dbListTables(ucsc)
ucsc_hg <- dbConnect(RMySQL::MySQL(), dbname="hg19", host="genome-mysql.cse.ucsc.edu", user = "genome")
dbListTables(ucsc_hg)
allTables <- dbListTables(ucsc_hg)
length(allTables)
allTables[1:5]
dbListFields(hg19, "affyU133Plus2")
dbListFields(ucsc_hg, "affyU133Plus2")
dbGetQuery(ucsc_hg, "select count(*) from affyU133Plus2")
affyData <- dbReadTable(ucsc_hg, "affyU133Plus2")
warnings()
head(affyData)
query <- dbSendQuery(ucsc_hg, "select * from affyU133Plus2 where misMatches between 1 and 3")
affyMis <- fetch(query);quantile((affyMis$misMatches))
affyMisSmall <- fetch(query, n=10); dbClearResult(query)
dim(affyMisSmall)
dbDisconnect(ucsc)
dbDisconnect(ucsc_hg)
source("http://bioconductor.org/biocLite.R")
biocLite("rhdf5")
biocLite("rhdf5")
library(rhdf5)
created = h5createFile("example.h5")
created = h5createGroup("example.h5","foo")
created = h5createGroup("example.h5","baa")
created = h5createGroup("example.h5","foo/foobaa")
h5ls("example.h5")
A = matrix(1:10,nr=5,nc=2)
h5write(A, "example.h5","foo/A")
B = array(seq(0.1,2.0,by=0.1),dim=c(5,2,2))
attr(B, "scale") <- "liter"
h5write(B, "example.h5","foo/foobaa/B")
h5ls("example.h5")
library(XML)
install.packages("RCurl")
library(RCurl)
con = url("http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en")
htmlCode = readLines(con)
close(con)
htmlCode
url <- "https://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
html <- htmlTreeParse(url, useInternalNodes=T)
url <- "http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
html <- htmlTreeParse(url, useInternalNodes=T)
url <- getURL("https://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en",ssl.verifyPeer=FALSE)
html <- htmlTreeParse(url, useInternalNodes=T)
xpathSApply(html, "//title", xmlValue)
xpathSApply(html, "//td[@id='col-citedby']", xmlValue)
l<-xpathSApply(html, "//td[@id='col-citedby']", xmlValue)
l
html
url <- getURL("https://scholar.google.com/citations?user=HI-I6C0AAAAJ&amp;hl=en",ssl.verifyPeer=FALSE)
xpathSApply(html, "//title", xmlValue)
l<-xpathSApply(html, "//td[@id='col-citedby']", xmlValue)
l
url <- "https://scholar.google.com/citations?user=HI-I6C0AAAAJ&amp;hl=en"
url <- getURL("https://scholar.google.com/citations?user=HI-I6C0AAAAJ&amp;hl=en")
html <- htmlTreeParse(url, useInternalNodes=T)
xpathSApply(html, "//title", xmlValue)
xpathSApply(html, "//td[@id='col-citedby']", xmlValue)
html <- htmlParse(url, useInternalNodes=T)
xpathSApply(html, "//title", xmlValue)
xpathSApply(html, "//td[@class = 'gsc_a_c']", xmlValue)
library(httr)
html2 = GET(url)
html2 <- GET(url)
url
url <- getURL("https://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en")
html2 <- GET(url)
url <- "https://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
html2 <- GET(url)
content2 = content(html2,as="text")
parsedHtml = htmlParse(content2,asText=TRUE)
xpathSApply(parsedHtml, "//title", xmlValue)
xpathSApply(parsedHtml, "//td[@class = 'gsc_a_c']", xmlValue)
pg1 = GET("http://httpbin.org/basic-auth/user/passwd")
pg1
pg2 = GET("http://httpbin.org/basic-auth/user/passwd", authenticate("user","passwd"))
names(pg2)
google = handle("http://google.com")
pg1 = GET(handle=google,path="/")
pg2 = GET(handle=google,path="search")
library("curl", lib.loc="/Library/Frameworks/R.framework/Versions/3.5/Resources/library")
library("data.table", lib.loc="/Library/Frameworks/R.framework/Versions/3.5/Resources/library")
library(readr)
getdata_data_EDSTATS_Country <- read_csv("~/Professional/DataScience/Course3/data/getdata_data_EDSTATS_Country.csv")
View(getdata_data_EDSTATS_Country)
library(readr)
getdata_data_GDP <- read_csv("~/Professional/DataScience/Course3/data/getdata_data_GDP.csv")
View(getdata_data_GDP)
library(readr)
getdata_data_GDP <- read_csv("~/Professional/DataScience/Course3/data/getdata_data_GDP.csv",
col_types = cols(X2 = col_integer()),
skip = 4)
View(getdata_data_GDP)
library(readr)
dataset <- read_csv(NULL)
View(dataset)
library(readr)
getdata_data_EDSTATS_Country <- read_csv("~/Professional/DataScience/Course3/data/getdata_data_EDSTATS_Country.csv")
View(getdata_data_EDSTATS_Country)
View(getdata_data_EDSTATS_Country)
newDF <- merge(getdata_data_EDSTATS_Country, getdata_data_GDP, by.x = "Country Code", by.y = "X1, all=FALSE")
newDF <- merge(getdata_data_EDSTATS_Country, getdata_data_GDP, by.x = "Country Code", by.y = "X1", all=FALSE)
newDF <- merge(getdata_data_EDSTATS_Country, getdata_data_GDP, by.x = "CountryCode", by.y = "X1", all=FALSE)
View(newDF)
View(getdata_data_GDP)
View(getdata_data_GDP)
View(getdata_data_EDSTATS_Country)
View(newDF)
cleanGDPRank <- filter(newDF, !is.na(X2))
cleanGDPRank <- filter(getdata_data_GDP, !is.na(X2))
cleanGDPRank <- filter(getdata_data_GDP, !is.na(X1))
cleanGDPRank <- filter(getdata_data_GDP, !is.na(getdata_data_GDP$X1))
library("dplyr", lib.loc="/Library/Frameworks/R.framework/Versions/3.5/Resources/library")
cleanGDPRank <- filter(getdata_data_GDP, !is.na(X1))
View(cleanGDPRank)
cleanGDPRank <- filter(getdata_data_GDP, (!is.na(X1) | !is.na(X2))
)
View(cleanGDPRank)
cleanGDPRank <- filter(getdata_data_GDP, !is.na(X2) )
View(getdata_data_GDP)
merge(cleanGDPRank, getdata_data_EDSTATS_Country, by.x = "X1", by.y = "CountryCode", all=FALSE)
newDF <- merge(cleanGDPRank, getdata_data_EDSTATS_Country, by.x = "X1", by.y = "CountryCode", all=FALSE)
View(newDF)
newDF <- arrange(newDF, X2)
View(newDF)
newDF <- arrange(newDF, desc(X2))
View(newDF)
group_by(newDF, "Income Group")
source('~/Professional/DataScience/Course3/Week3.R')
source('~/Professional/DataScience/Course3/Week3.R')
View(newDF_IG)
source('~/Professional/DataScience/Course3/Week3.R')
View(newDF_IG)
source('~/Professional/DataScience/Course3/Week3.R')
View(newDF_IG)
View(newDF_IG)
source('~/Professional/DataScience/Course3/Week3.R')
source('~/Professional/DataScience/Course3/Week3-q5.R')
View(newDF_IG2)
source('~/Professional/DataScience/Course3/Week3-q5.R')
View(newDF_IG2)
source('~/Professional/DataScience/Course3/Week3-q5.R')
source('~/Professional/DataScience/Course3/Week3-q5.R')
source('~/Professional/DataScience/Course3/Week3-q5.R')
View(newDF_IG2)
ntile(newDF_IG2, 5)
source('~/Professional/DataScience/Course3/Week3-q5.R')
View(newDF_five)
library(reshape2)
ls()
rm(list=ls())
(swirl)
library(swirl)
swirl()
Sys.getlocale("LC_TIME")
library(lubridate)
help(package = lubridate)
this_day <- today()
this_day
year(this_day)
wday(this_day)
wday(this_day, label=TRUE)
this_moment <- now()
this_moment
second(this_moment)
my_date <- ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
mdy("1989 May 17")
mdy("1989 May 17")
mdy("March 12, 1975")
dmy(25081985)
ymd("192012")
ymd("1920-1-2")
dt1
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
this_moment <- update(this_moment, hours = 11, minutes = 36, seconds = 55)
this_moment
nyc <- now(tzone = "America/New_York")
nyc
depart <- nyc + days(2)
depart
depart <- update(depart, hours=17, minures=34)
depart <- update(depart, hours=17, minutes=34)
depart
arrive <- depart + hours(15) + minutes(50)
?with_tz
arrive <- with_tz(arrive, "Asia/Hong_Kong")
arrive
last_time <- mdy("June 17, 2008", tz="Singapore")
last_time
?interval
last_time %--% arrive
how_long <- last_time %--% arrive
interval(last_time, end = arrive, tzone = tz(last_time))
interval(last_time, end = arrive)
how_long <- interval(last_time, end = arrive)
as.period(how_long)
stopwatch()
library(readr)
getdata_data_ss06hid <- read_csv("~/Professional/DataScience/Course3/data/getdata_data_ss06hid.csv")
View(getdata_data_ss06hid)
R <- getdata_data_ss06hid
strsplit(R, "wgtp")
strsplit(R, c("wgtp"))
strsplit(names(R), "wgtp")
number1 <- strsplit(names(R), "wgtp")
str(number1)
class(number1)
View(number1)
names(R)
library(readr)
getdata_data_GDP <- read_csv("~/Professional/DataScience/Course3/data/getdata_data_GDP.csv",
col_names = FALSE, skip = 5)
View(getdata_data_GDP)
GDPData <- getdata_data_GDP[1:190]
GDPData <- getdata_data_GDP[1:190,]
View(GDPData)
GDPData$X5 <- as.numeric(GDPData$X5)
> GDPData <- getdata_data_GDP[1:190,]
GDPData <- getdata_data_GDP[1:190,]
GDPData$X5 <- gsub(",", "",  GDPData$X5)
GDPData$X5 <- as.numeric(GDPData$X5)
mean(GDPData$X5)
countryNames <- GDPData$X4
grep("^United",countryNames), 3
grep("^United",countryNames)
grep("United$",countryNames)
c<-grep("United$",countryNames)
c
library(readr)
getdata_data_EDSTATS_Country <- read_csv("~/Professional/DataScience/Course3/data/getdata_data_EDSTATS_Country.csv")
View(getdata_data_EDSTATS_Country)
View(getdata_data_EDSTATS_Country)
View(GDPData)
allData <- merge(GDPData, getdata_data_EDSTATS_Country, by.x = "X1", by.y = "CountryCode")
View(allData)
fiscalString <- "Fiscal year end: June"
fiscalJune <- grep(fiscalString, allData[,19])
fiscalJune
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
install.packages("quantmod")
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)no
library(quantmod)
install.packages("quantmod")
amzn = getSymbols("AMZN",auto.assign=FALSE)
library(quantmod)
> install.packages('quantmod')
install.packages('quantmod')
library("curl", lib.loc="/Library/Frameworks/R.framework/Versions/3.5/Resources/library")
install.packages('quantmod')
install.packages(libcurl)
install.packages("zoo")
install.packages("zoo")
install.packages("quantmod")
amzn = getSymbols("AMZN",auto.assign=FALSE)
amzn <- getSymbols("AMZN",auto.assign=FALSE)
amzn <- getSymbols("AMZN")
library("quantmod")
amzn <- getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
head(sampleTimes)
grep("2012", sampleTimes)
str(sampleTimes)
sample2015 <- grep("2012", sampleTimes)
is2012 <- grep("2012", sampleTimes)
sample2012 <- sampleTimes[sample2012,]
sample2012 <- sampleTimes[,sample2012]
sample2012 <- sampleTimes[sample2012]
sample2012 <- sampleTimes[is2012]
sample2012_dates <- ymd(sample2012)
sample2012_days <- days(sample2012)
sample2012_days <- day(sample2012)
ls()
remove(list=ls())
source('~/GitHub/datasciencecoursera/Course3/run_analysis.R')
setwd("~/GitHub/datasciencecoursera/Course3")
source('~/GitHub/datasciencecoursera/Course3/run_analysis.R')
names_dash_to_under
gsub("\\(\\)", "", names(names_dash_to_under)
)
grep(["\\(\\)"], "", names(names_dash_to_under), value = TRUE)
grep("//(//)", "", names(names_dash_to_under), value = TRUE)
grep("\(\)", "", names(names_dash_to_under), value = TRUE)
grep("\\(\\)", "", names(names_dash_to_under), value = TRUE)
grep("()", "", names(names_dash_to_under), fixed = TRUE, value = TRUE)
source('~/GitHub/datasciencecoursera/Course3/run_analysis.R')
source('~/GitHub/datasciencecoursera/Course3/run_analysis.R')
names_no_paren
source('~/GitHub/datasciencecoursera/Course3/run_analysis.R')
source('~/GitHub/datasciencecoursera/Course3/run_analysis.R')
names_no_digits <- gsub("^[0-9]{1,3} ", names_no_paren)
names_no_digits <- gsub("^[0-9]{1,3} ", "", names_no_paren)
names_no_digits
source('~/GitHub/datasciencecoursera/Course3/run_analysis.R')
rename(activity_tidyframe,"angle(tBodyAccJerkMean,gravityMean)"="angle(tBodyAccJerkMean),gravityMean)")
View(activity_tidyframe)
str(activity_tidyframe)
grep("tBodyAccJerkMean),gravityMean", fixed=TRUE, value = TRUE)
grep("tBodyAccJerkMean),gravityMean", names(activity_tidyframe),fixed=TRUE, value = TRUE)
gsub("tBodyAccJerkMean),gravityMean","tBodyAccJerkMean,gravityMean" names(activity_tidyframe),fixed=TRUE)
